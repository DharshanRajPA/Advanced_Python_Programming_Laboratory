{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d870e997-5922-4637-8140-90a599d1af0c",
   "metadata": {},
   "source": [
    "# HANDLING CSV FILES.\n",
    "\n",
    "Student: Dharshan Raj P A  \n",
    "Register No: 22MIC0073  \n",
    "Lab 15 â€” CSV Handling Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe91151-7b42-425d-bd6f-c5c8c1ffead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Build an in-memory CSV representing patient vitals (small synthetic sample)\n",
    "PatientCsvText = \"\"\"PatientID,Name,Age,Gender,Diagnosis,BloodPressure,HeartRate\n",
    "P001,Arjun Mehra,45,Male,Hypertension,140/90,80\n",
    "P002,Meera Joshi,38,Female,Diabetes,130/85,76\n",
    "P003,Rahul Desai,50,Male,Cardiovascular Disease,150/95,85\n",
    "P004,Nandini Iyer,29,Female,Asthma,120/80,72\n",
    "P005,Viraj Kapoor,60,Male,Arthritis,135/88,78\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV text into a DataFrame\n",
    "PatientRecordsFrame = pd.read_csv(io.StringIO(PatientCsvText))\n",
    "print(PatientRecordsFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce35069-31c6-490b-b06d-a3fdaa90bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file named 'patient_data.csv' without row indices\n",
    "PatientRecordsFrame.to_csv(\"patient_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a04a6-97fc-4419-9a8a-1885986fcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few records to get a quick preview of the dataset\n",
    "print(PatientRecordsFrame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f69f34-e6b2-4ecb-bcc8-768b22eef7d8",
   "metadata": {},
   "source": [
    "# EXTRACTING CSV INTO PANDAS DATAFRAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31c3c1-b41e-446d-bce4-99c69df71156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a concise summary of the DataFrame: types, non-nulls, memory\n",
    "print(PatientRecordsFrame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1683-ddf4-4955-9544-1644fc38e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PatientRecordsFrame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee28ed-9320-4df1-99db-72b989d68cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PatientRecordsFrame.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921aec1-2b1f-45ac-8e63-aaad9682b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PatientRecordsFrame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32880a-f65b-48e7-89af-f587dd412c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print raw NumPy array of DataFrame values\n",
    "print(PatientRecordsFrame.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d019e35-d563-46a2-a66d-188284a64a19",
   "metadata": {},
   "source": [
    "# EXCEPTION HANDLING WHILE EXTRACTING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550fe56-282c-49e3-a309-bd3c229d451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into DataFrame with simple exception handling\n",
    "import pandas as pd\n",
    "try:\n",
    "    PatientDataSafe = pd.read_csv(\"patient_data.csv\")  # reading csv file\n",
    "    print(PatientDataSafe.head())  # displaying top 5 rows\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found at the location\")  # handling errors in a customised way\n",
    "except Exception as e:\n",
    "    print(f\"Error occured: {e}\")  # displaying the error message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b727d-49bf-4496-a55a-6be6bca708c3",
   "metadata": {},
   "source": [
    "# 1.READ A CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56c85a-1b92-4ae2-9d66-1a600b12815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the patient dataset from the CSV file into a DataFrame\n",
    "PatientDataFrame = pd.read_csv(\"patient_data.csv\")\n",
    "\n",
    "# Display the full contents of the DataFrame\n",
    "print(PatientDataFrame)  # Intentionally printing entire DataFrame for this exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b13ef-3955-4c80-b05e-98c8326bb3a1",
   "metadata": {},
   "source": [
    "# 2.READ A CSV FILE CHUNK BY CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86629794-b5a1-4dcc-8b69-8f8ae167ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChunkSize = 2   # Smaller size used here for demonstration since dataset is small\n",
    "ChunkCounter = 1\n",
    "\n",
    "# Process the patient data file in smaller segments instead of reading it all at once\n",
    "for DataChunk in pd.read_csv(\"patient_data.csv\", chunksize=ChunkSize):  # Read 2 rows at a time\n",
    "    print(f\"Patient Data Chunk {ChunkCounter}:\")\n",
    "    print(DataChunk)\n",
    "    ChunkCounter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8aeefc-c2e3-48a0-9ad3-b460415a82b9",
   "metadata": {},
   "source": [
    "# ALTERNATE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d90bf-4664-442b-b932-0aff0430346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Process the patient dataset file incrementally in chunks of 2 rows\n",
    "with pd.read_csv(\"patient_data.csv\", chunksize=2) as Reader:\n",
    "    print(Reader)  # Display the TextFileReader object reference\n",
    "    \n",
    "    # Iterate through each chunk and display the first 2 rows of the chunk\n",
    "    for Chunk in Reader:\n",
    "        print(Chunk.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fb1a1-75f7-483f-ac08-c494b947dde0",
   "metadata": {},
   "source": [
    "# USAGE OF ENUMERATE METHOD FOR CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15cc60-412d-40c0-bc6e-aa16998049b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ChunkSize = 2  # Small chunk size for demonstration purposes\n",
    "\n",
    "# Loop through the patient data file in small chunks with an index counter\n",
    "for ChunkIndex, Chunk in enumerate(pd.read_csv(\"patient_data.csv\", chunksize=ChunkSize)):\n",
    "    print(f\"\\n--- Patient Data Chunk {ChunkIndex + 1} ---\")\n",
    "    print(Chunk.head(2))   # Display the first two records in the current chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f971a0-90df-4442-99dd-23f5116614c9",
   "metadata": {},
   "source": [
    "# 3. APPEND TO A CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3253ef-28a6-40a0-958f-2c4d857b660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define new patient records to be added\n",
    "NewPatientData = {\n",
    "    \"PatientID\": [\"P006\", \"P007\"],\n",
    "    \"Name\": [\"Leena Patel\", \"Rohan Singh\"],\n",
    "    \"Age\": [55, 42],\n",
    "    \"Gender\": [\"Female\", \"Male\"],\n",
    "    \"Diagnosis\": [\"Diabetes\", \"Hypertension\"],\n",
    "    \"BloodPressure\": [\"128/85\", \"145/92\"],\n",
    "    \"HeartRate\": [79, 82]\n",
    "}\n",
    "\n",
    "NewPatientFrame = pd.DataFrame(NewPatientData)\n",
    "\n",
    "# Add the new patient records to the existing patient data file\n",
    "NewPatientFrame.to_csv(\"patient_data.csv\", mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38617047-de1b-4a30-9f66-a47cc08c4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last two newly added records from the new DataFrame\n",
    "LastTwoNew = NewPatientFrame.tail(2)\n",
    "print(\"Last 2 newly created patient records:\")\n",
    "print(LastTwoNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130f3d8-2ea0-4980-8af9-71045956df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the last two rows using index positions\n",
    "LastTwoNewAlt = NewPatientFrame.iloc[-2:]\n",
    "print(\"\\nLast 2 records accessed by index position:\")\n",
    "print(LastTwoNewAlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cce16b-f44f-4838-8151-4f047a81aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate reading from the full dataset after appending new data\n",
    "FullPatientData = pd.concat([PatientDataFrame, NewPatientFrame], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b95119-64a1-471c-8509-a89d152b5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the newly added rows by their PatientID values\n",
    "AccessRows = FullPatientData[FullPatientData[\"PatientID\"].isin([\"P006\", \"P007\"])]\n",
    "print(\"\\nNewly added patient records accessed by PatientID:\")\n",
    "print(AccessRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdc6da-722c-4747-998d-d2b4dc0dfc47",
   "metadata": {},
   "source": [
    "# 4.WRITE NUMERIC DATA INTO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc24176-d25c-4b26-8b58-ff5b0a811cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataset simulating sensor measurements\n",
    "SensorDataFrame = pd.DataFrame({\n",
    "    \"SensorID\": np.arange(101, 111),  # Sensor IDs from 101 to 110\n",
    "    \"Temperature_C\": np.random.randint(20, 35, size=10),    # Temperature values in Celsius\n",
    "    \"Humidity_%\": np.random.uniform(30.0, 90.0, size=10).round(2)  # Humidity in percentage\n",
    "})\n",
    "\n",
    "# Save the sensor data to a CSV file\n",
    "SensorDataFrame.to_csv(\"sensor_data.csv\", index=False)\n",
    "\n",
    "print(\"Sensor data CSV file created successfully!\")\n",
    "print(SensorDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2557e3-1aa2-48f1-8198-b2c7f39a1661",
   "metadata": {},
   "source": [
    "# 5.WRITE TEXT DATA INTO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0827685-c3c6-4e49-9c6f-0964f9e44042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataset with book details\n",
    "BookCatalogFrame = pd.DataFrame({\n",
    "    \"Title\": [\"The Alchemist\", \"1984\", \"To Kill a Mockingbird\", \"The Great Gatsby\", \"Moby Dick\"],\n",
    "    \"Author\": [\"Paulo Coelho\", \"George Orwell\", \"Harper Lee\", \"F. Scott Fitzgerald\", \"Herman Melville\"],\n",
    "    \"Genre\": [\"Fiction\", \"Dystopian\", \"Classic\", \"Classic\", \"Adventure\"]\n",
    "})\n",
    "\n",
    "# Save the book information into a CSV file\n",
    "BookCatalogFrame.to_csv(\"book_data.csv\", index=False)\n",
    "\n",
    "print(\"Book data CSV written successfully!\")\n",
    "print(BookCatalogFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ca0fd-0b60-43be-acd1-39edcbfd8dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
